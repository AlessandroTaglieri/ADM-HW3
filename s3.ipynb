{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from itertools import islice\n",
    "import csv\n",
    "\n",
    "#CREATEB INDEX3              \n",
    "\n",
    "dict2 = {}\n",
    "count=0\n",
    "present=False\n",
    "with open('HW3 ADM/tsv/vocobulary.tsv', 'r', newline='') as f_output:\n",
    "        tsv_vocabulary = list(csv.reader(f_output, delimiter='\\t'))\n",
    "        name=\"aritcle_\"\n",
    "        extension2=\".tsv\"\n",
    "        h=0\n",
    "        for row in tsv_vocabulary:\n",
    "            \n",
    "            dict2[row[1]]=[]\n",
    "        for index in range(len(listUrl_Movies3)):\n",
    "            h+=1\n",
    "            print(h)\n",
    "            file=\"{}{}{}\".format(name,index,extension2)\n",
    "            with open(\"HW3 ADM/tsv_correct/\"+file,\"r\") as tsvfile:\n",
    "                data_list = list(csv.reader(tsvfile, delimiter=\"\\t\"))\n",
    "                tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "                intro=data_list[1][1]\n",
    "                intro = ast.literal_eval(intro)\n",
    "                plot=data_list[1][2]\n",
    "                plot = ast.literal_eval(plot)\n",
    "                music=data_list[1][8]\n",
    "                music = ast.literal_eval(music)\n",
    "                text=plot+intro+music\n",
    "                text= list(set(map(str.lower, text)))\n",
    "                \n",
    "                #for evry words in plot adn intro (for every page) we get every word. From every word we get its term_id and put it whit their occurences (document_id) in dict2\n",
    "                for i in text:\n",
    "                    for row in tsv_vocabulary:\n",
    "                        if i==row[0]:\n",
    "                            doc=\"document_\"\n",
    "                            name2=\"{}{}\".format(doc,index)\n",
    "                            \n",
    "                            dict2[row[1]].append(name2)\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "                            \n",
    "        #put dict2 in index.tsv file. In. evry row we have a single term_id with occurences of respective word.\n",
    "        with open('HW3 ADM/tsv/index3.tsv', 'w', newline='') as f_output:\n",
    "            tsv_vocabulary = csv.writer(f_output, delimiter='\\t')           \n",
    "            for key, val in dict2.items():\n",
    "                tsv_vocabulary.writerow([key, val])           \n",
    "                    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION THAT GIVE US DOCUMENT FOR SEARCH ENGINE 3\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "import ast\n",
    "#define function that allows us to calculate a list that is an intersection from two list\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) \n",
    "def getDocuments2(words):\n",
    "\n",
    "\n",
    "    #we use dict3 to store term_id and its respective documents_id\n",
    "    dict3={}\n",
    "    ##we use dict4 to store evry word and its respective documents_id\n",
    "    dict4={}\n",
    "    csv.field_size_limit(sys.maxsize)\n",
    "    #in listWords we have a list that contains all words about inout query\n",
    "    listWords = words.split()\n",
    "    listWords=[x.lower() for x in listWords]\n",
    "\n",
    "    #with vocabulary.tsv we start to build a dict3 with term_id for every words in wordsList\n",
    "    with open('HW3 ADM/tsv/vocobulary.tsv', 'r', newline='') as f_output:\n",
    "        tsv_vocabulary = list(csv.reader(f_output, delimiter='\\t'))\n",
    "        for word in listWords:\n",
    "            word=word.lower()\n",
    "            present=False\n",
    "            for row in tsv_vocabulary:\n",
    "                if word.lower()==row[0]:\n",
    "                    dict3[row[1]]=[]\n",
    "                    present=True\n",
    "            #case where word is not in vocabulary\n",
    "            if present==False:\n",
    "                dict4[word]=[]\n",
    "\n",
    "        #we continue to match documnets_id to every term_id in dict3\n",
    "        with open('HW3 ADM/tsv/index3.tsv', 'r', newline='') as f_output:\n",
    "            tsv_index = list(csv.reader(f_output, delimiter='\\t'))\n",
    "            for k in dict3.keys():  \n",
    "                for row in tsv_index:\n",
    "                    if row[0]==k:\n",
    "                        dict3[k]=row[1]\n",
    "                        continue\n",
    "\n",
    "\n",
    "        #finally we build dict4 where evry word matches to respective documents_id\n",
    "        for k in dict3.keys():\n",
    "\n",
    "            for row in tsv_vocabulary:\n",
    "                if k==row[1]:\n",
    "                    dict4[row[0]]=dict3[row[1]]\n",
    "\n",
    "        document=ast.literal_eval(dict4[listWords[0]])         \n",
    "        #interection between every list in values dict4. In this way we have documnets_id where all words (in query input) are present\n",
    "        for value in dict4.values():\n",
    "            document=intersection(document,ast.literal_eval(value))\n",
    "        #print(document)\n",
    "    return document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def search3(query):\n",
    "    \n",
    "    document=getDocuments2(query)\n",
    "    listWords = query.split()\n",
    "    listWords=[x.lower() for x in listWords]\n",
    "    df=pd.DataFrame(columns=['title', 'intro', 'plot', 'music', 'score'])\n",
    "    df_score=pd.DataFrame(columns=['title_score', 'intro_score', 'plot_score', 'music_score'])\n",
    "    scores=[0.8,0.4,0.3,0.6]\n",
    "    df_score.loc[0]=scores\n",
    "\n",
    "    for index in range(len(document)):\n",
    "        score=0\n",
    "        #get id of documnets_is\n",
    "        numberDocument=document[index][9:]\n",
    "        #get wikipedia url\n",
    "        url=listUrl_Movies3[int(numberDocument)]\n",
    "        name=\"aritcle_\"\n",
    "        extension2=\".tsv\"\n",
    "        index=int(numberDocument)\n",
    "        file=\"{}{}{}\".format(name,index,extension2)\n",
    "        #get info about title and intro for evert film that corresponds to every documents_id\n",
    "        with open(\"HW3 ADM/tsv_correct/\"+file,\"r\") as tsvfile:\n",
    "                    tsv_index = list(csv.reader(tsvfile, delimiter='\\t'))\n",
    "                    title=ast.literal_eval(tsv_index[1][3])\n",
    "                    \n",
    "                    intro=ast.literal_eval(tsv_index[1][1])\n",
    "\n",
    "                    plot=ast.literal_eval(tsv_index[1][2])\n",
    "                    \n",
    "                    music=ast.literal_eval(tsv_index[1][8])\n",
    "                   \n",
    "                    \n",
    "                    if (all(elem in title  for elem in listWords)) or (all(elem in listWords  for elem in title)):\n",
    "                            score+=df_score.loc[0]['title_score']\n",
    "                            print('title')\n",
    "                    if all(elem in intro  for elem in listWords)==True:\n",
    "                            score+=df_score.loc[0]['intro_score']\n",
    "                            \n",
    "                    if all(elem in plot  for elem in listWords)==True:\n",
    "                            score+=df_score.loc[0]['plot_score']\n",
    "                            \n",
    "                    if any(elem in music  for elem in listWords)==True:\n",
    "                        \n",
    "                        score+=df_score.loc[0]['music_score']\n",
    "                    \n",
    "\n",
    "        with open('HW3 ADM/tsv/'+file, 'r', newline='') as f_output:\n",
    "            tsv_file = list(csv.reader(f_output, delimiter='\\t'))\n",
    "            title2=tsv_file[1][3]\n",
    "            intro2=tsv_file[1][1]\n",
    "            plot2=tsv_file[1][2]\n",
    "            music2=tsv_file[1][8]\n",
    "            film=[title2,intro2,plot2,music2,score]\n",
    "            df.loc[index] = film\n",
    "           \n",
    "\n",
    "    ndf=df.sort_values('score', ascending=False)\n",
    "    scores\n",
    "    #print(dict4.keys())\n",
    "    return ndf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#EXECUTE SEARCH3\n",
    "\n",
    "query='Levi'\n",
    "search3(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
